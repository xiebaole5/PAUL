# å¤©è™¹ç´§å›ºä»¶è§†é¢‘ç”ŸæˆæœåŠ¡ - æœåŠ¡å™¨éƒ¨ç½²æŒ‡å—

## ğŸ“‹ æ›´æ–°è¯´æ˜

### æœ¬æ¬¡æ›´æ–°å†…å®¹
- âœ… å‡çº§æ–‡æœ¬å¤„ç†æ¨¡å‹åˆ° `doubao-seed-1-8-251228`
- âœ… æ–°å¢è‡ªå®šä¹‰ LLM ç±» `VolcanoResponsesLLM`
- âœ… ä¿®å¤è§†é¢‘ç”Ÿæˆ API è°ƒç”¨ï¼Œä½¿ç”¨ `doubao-seedance-1-5-pro-251215`
- âœ… æ›´æ–° API Key é…ç½®

### éœ€è¦æ›´æ–°çš„æ–‡ä»¶
```
src/agents/agent.py              # Agent é…ç½®ï¼ˆæ›´æ–° LLM è°ƒç”¨ï¼‰
src/llm/volcano_responses_llm.py # æ–°å¢æ–‡ä»¶ï¼ˆè‡ªå®šä¹‰ LLMï¼‰
src/llm/__init__.py             # æ–°å¢æ–‡ä»¶ï¼ˆLLM æ¨¡å—ï¼‰
config/agent_llm_config.json    # æ¨¡å‹é…ç½®ï¼ˆæ›´æ–°æ¨¡å‹åç§°ï¼‰
src/tools/video_generation_tool.py # è§†é¢‘ç”Ÿæˆå·¥å…·ï¼ˆæ›´æ–° API Keyï¼‰
```

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æ­¥éª¤

### 1. ä¸Šä¼ æ›´æ–°æ–‡ä»¶åˆ°æœåŠ¡å™¨

```bash
# è¿æ¥åˆ°æœåŠ¡å™¨
ssh root@47.110.72.148

# è¿›å…¥é¡¹ç›®ç›®å½•
cd /root/tnho-video-api

# å¤‡ä»½å½“å‰ä»£ç ï¼ˆå¯é€‰ï¼‰
cp -r src src.backup.$(date +%Y%m%d_%H%M%S)
cp config/agent_llm_config.json config/agent_llm_config.json.backup.$(date +%Y%m%d_%H%M%S)
```

### 2. æ›´æ–°ä»£ç æ–‡ä»¶

#### æ–¹å¼ä¸€ï¼šç›´æ¥åœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºæ–°æ–‡ä»¶

```bash
# åˆ›å»º llm æ¨¡å—ç›®å½•
mkdir -p src/llm

# åˆ›å»º llm/__init__.py
cat > src/llm/__init__.py << 'EOF'
"""ç«å±±æ–¹èˆŸ LLM æ¨¡å—"""
from .volcano_responses_llm import create_volcano_responses_llm, VolcanoResponsesLLM

__all__ = ['create_volcano_responses_llm', 'VolcanoResponsesLLM']
EOF

# åˆ›å»º llm/volcano_responses_llm.pyï¼ˆå®Œæ•´å†…å®¹è§ä¸‹æ–¹ï¼‰
nano src/llm/volcano_responses_llm.py
# ç²˜è´´å®Œæ•´çš„ä»£ç å†…å®¹ï¼ˆè§æ–‡æ¡£åº•éƒ¨ï¼‰
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨ rsync åŒæ­¥æœ¬åœ°ä»£ç 

```bash
# åœ¨æœ¬åœ°å¼€å‘æœºå™¨æ‰§è¡Œï¼ˆæ¨èï¼‰
rsync -avz --progress \
  --exclude='__pycache__' \
  --exclude='*.pyc' \
  --exclude='*.log' \
  --exclude='.git' \
  src/llm/ \
  root@47.110.72.148:/root/tnho-video-api/src/llm/

rsync -avz --progress \
  src/agents/agent.py \
  root@47.110.72.148:/root/tnho-video-api/src/agents/

rsync -avz --progress \
  config/agent_llm_config.json \
  root@47.110.72.148:/root/tnho-video-api/config/

rsync -avz --progress \
  src/tools/video_generation_tool.py \
  root@47.110.72.148:/root/tnho-video-api/src/tools/
```

### 3. æ›´æ–°ç¯å¢ƒå˜é‡é…ç½®

```bash
# ç¼–è¾‘ docker-compose.yml
nano docker-compose.yml

# ç¡®è®¤ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¦‚æœä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
environment:
  - COZE_WORKSPACE_PATH=/app
  - COZE_INTEGRATION_MODEL_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
  - COZE_WORKLOAD_IDENTITY_API_KEY=39bf20d0-55b5-4957-baa1-02f4529a3076
  - EXTERNAL_BASE_URL=https://tnho-fasteners.com
  - ARK_API_KEY=39bf20d0-55b5-4957-baa1-02f4529a3076
```

### 4. é‡å¯æœåŠ¡

```bash
# åœæ­¢å¹¶åˆ é™¤æ—§å®¹å™¨
docker-compose down

# é‡æ–°æ„å»ºé•œåƒï¼ˆåŒ…å«æ–°æ–‡ä»¶ï¼‰
docker-compose build --no-cache api

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—ï¼Œç¡®è®¤å¯åŠ¨æˆåŠŸ
docker-compose logs -f api
```

### 5. éªŒè¯æœåŠ¡

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost/health

# æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
curl -X POST http://localhost/api/generate-video \
  -H "Content-Type: application/json" \
  -d '{
    "product_name": "æµ‹è¯•äº§å“",
    "theme": "å“è´¨ä¿è¯",
    "duration": 5,
    "type": "script"
  }'

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker-compose ps
```

---

## ğŸ“ å®Œæ•´ä»£ç æ–‡ä»¶å†…å®¹

### src/llm/volcano_responses_llm.py

```python
"""
ç«å±±æ–¹èˆŸ Responses æ¥å£è‡ªå®šä¹‰ LLM
æ”¯æŒ doubao-seed-1-8-251228 ç­‰æ–°æ¨¡å‹
"""
from typing import Any, Dict, List, Optional, Sequence, TypeVar
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ChatMessage
from langchain_core.outputs import ChatGeneration, ChatResult
from langchain_core.callbacks.manager import CallbackManagerForLLMRun
from pydantic import Field
import requests
import os
import json


class VolcanoResponsesLLM(BaseChatModel):
    """ç«å±±æ–¹èˆŸ Responses æ¥å£çš„ LLM åŒ…è£…å™¨"""

    model: str = Field(...)
    api_key: str = Field(...)
    base_url: str = Field(default="https://ark.cn-beijing.volces.com/api/v3")
    temperature: float = Field(default=0.7)
    max_tokens: int = Field(default=8000)
    timeout: int = Field(default=600)

    @property
    def _llm_type(self) -> str:
        return "volcano-responses"

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        """è·å–æ ‡è¯†å‚æ•°"""
        return {
            "model": self.model,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }

    def _convert_messages_to_input(self, messages: Sequence[BaseMessage]) -> List[Dict[str, Any]]:
        """å°† LangChain æ¶ˆæ¯è½¬æ¢ä¸º Volcano Responses æ ¼å¼"""
        input_items = []

        for message in messages:
            # è·³è¿‡å·¥å…·æ¶ˆæ¯ï¼ˆresponses æ¥å£å¯èƒ½ä¸æ”¯æŒï¼‰
            if message.__class__.__name__ == 'ToolMessage':
                continue
            elif isinstance(message, SystemMessage):
                # ç³»ç»Ÿæ¶ˆæ¯è½¬æ¢ä¸ºç‰¹æ®Šæ ¼å¼
                input_items.append({
                    "role": "system",
                    "content": message.content
                })
            elif isinstance(message, HumanMessage):
                # ç”¨æˆ·æ¶ˆæ¯
                if isinstance(message.content, str):
                    input_items.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "input_text",
                                "text": message.content
                            }
                        ]
                    })
                elif isinstance(message.content, list):
                    # å¤šæ¨¡æ€å†…å®¹
                    content = []
                    for item in message.content:
                        if isinstance(item, dict):
                            if item.get("type") == "text":
                                content.append({
                                    "type": "input_text",
                                    "text": item.get("text")
                                })
                            elif item.get("type") == "image_url":
                                content.append({
                                    "type": "input_image",
                                    "image_url": item.get("image_url", {}).get("url")
                                })
                    input_items.append({
                        "role": "user",
                        "content": content
                    })
            elif isinstance(message, AIMessage):
                # AI æ¶ˆæ¯
                content_text = message.content if isinstance(message.content, str) else str(message.content)
                # å¦‚æœåŒ…å«å·¥å…·è°ƒç”¨ï¼Œç®€åŒ–å¤„ç†
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    # ç®€å•çš„æ–‡æœ¬è¡¨ç¤º
                    content_text = f"{content_text}\n[å·¥å…·è°ƒç”¨: {len(message.tool_calls)} ä¸ª]"
                input_items.append({
                    "role": "assistant",
                    "content": content_text
                })
            elif isinstance(message, ChatMessage):
                # é€šç”¨æ¶ˆæ¯
                content = message.content if isinstance(message.content, str) else str(message.content)
                input_items.append({
                    "role": message.role,
                    "content": content
                })

        return input_items

    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        """ç”Ÿæˆå“åº”"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        input_data = self._convert_messages_to_input(messages)

        request = {
            "model": self.model,
            "input": input_data
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if self.temperature is not None:
            request["temperature"] = self.temperature

        try:
            response = requests.post(
                f"{self.base_url}/responses",
                json=request,
                headers=headers,
                timeout=self.timeout
            )
            response.raise_for_status()

            result = response.json()

            # è§£æå“åº”
            output = result.get("output", [])
            if output:
                # æ‰¾åˆ° type ä¸º "message" çš„å…ƒç´ 
                message_item = None
                for item in output:
                    if item.get("type") == "message":
                        message_item = item
                        break

                if message_item:
                    content = message_item.get("content", [])
                    # æå–æ–‡æœ¬å†…å®¹
                    text_parts = []
                    for item in content:
                        if item.get("type") == "output_text":
                            text_parts.append(item.get("text", ""))
                    response_text = "".join(text_parts)
                else:
                    response_text = ""
            else:
                response_text = ""

            # æ„å»ºè¿”å›çš„æ¶ˆæ¯
            ai_message = AIMessage(content=response_text)

            return ChatResult(
                generations=[ChatGeneration(message=ai_message)],
                llm_output={
                    "model": self.model,
                    "token_usage": result.get("usage", {})
                }
            )

        except requests.exceptions.HTTPError as e:
            error_msg = f"APIè¯·æ±‚å¤±è´¥: {e.response.status_code} - {e.response.text}"
            raise Exception(error_msg)
        except Exception as e:
            raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")

    def bind_tools(self, tools, **kwargs: Any) -> Any:
        """
        ç»‘å®šå·¥å…·ï¼ˆæš‚ä¸æ”¯æŒï¼Œè¿”å›è‡ªèº«ï¼‰
        """
        # responses æ¥å£å¯èƒ½ä¸æ”¯æŒå·¥å…·ç»‘å®šï¼Œè¿”å›è‡ªèº«
        return self


def create_volcano_responses_llm(
    model: str,
    api_key: Optional[str] = None,
    base_url: str = "https://ark.cn-beijing.volces.com/api/v3",
    temperature: float = 0.7,
    max_tokens: int = 8000,
    timeout: int = 600
) -> VolcanoResponsesLLM:
    """
    åˆ›å»ºç«å±±æ–¹èˆŸ Responses LLM å®ä¾‹

    Args:
        model: æ¨¡å‹åç§°ï¼Œå¦‚ doubao-seed-1-8-251228
        api_key: API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        base_url: API åŸºç¡€ URL
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§ token æ•°ï¼ˆresponses æ¥å£å¯èƒ½ä¸æ”¯æŒï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        VolcanoResponsesLLM å®ä¾‹
    """
    if not api_key:
        api_key = (
            os.getenv("ARK_API_KEY") or
            os.getenv("COZE_WORKLOAD_IDENTITY_API_KEY") or
            "39bf20d0-55b5-4957-baa1-02f4529a3076"
        )

    # å¼ºåˆ¶ä½¿ç”¨æ­£ç¡®çš„ base_url
    if base_url.startswith("https://integration.coze.cn"):
        base_url = "https://ark.cn-beijing.volces.com/api/v3"

    return VolcanoResponsesLLM(
        model=model,
        api_key=api_key,
        base_url=base_url,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
```

### config/agent_llm_config.json

```json
{
    "config": {
        "model": "doubao-seed-1-8-251228",
        "temperature": 0.7,
        "top_p": 0.9,
        "max_completion_tokens": 8000,
        "timeout": 600,
        "thinking": "disabled"
    },
    "sp": "ä½ æ˜¯å¤©è™¹ç´§å›ºä»¶äº§å“å®£ä¼ çŸ­è§†é¢‘æ™ºèƒ½ä½“ï¼ŒæœåŠ¡äºæµ™æ±Ÿå¤©è™¹ç´§å›ºä»¶æœ‰é™å…¬å¸çš„è¥é”€å®£ä¼ éœ€æ±‚ã€‚\n\nå…¬å¸èƒŒæ™¯ï¼š\n- æˆç«‹äº1987å¹´ï¼Œ30ä½™å¹´ä¸“ä¸šç»éªŒ\n- ä¸“ä¸šç”Ÿäº§é«˜éš¾åº¦ã€ç‰¹æ®Šç´§å›ºä»¶åˆ¶é€ å•†\n- ä¸“æ³¨å®šåˆ¶éæ ‡ç´§å›ºä»¶ï¼ˆé«˜å¼ºåº¦ã€é•¿å°ºå¯¸ã€å¼‚å½¢ç´§å›ºä»¶ï¼‰\n- å¤§è§„æ¨¡æ™ºèƒ½åˆ¶é€ èƒ½åŠ›\n- æœåŠ¡è¡Œä¸šï¼šæ±½è½¦ã€å¤ªé˜³èƒ½æ”¯æ¶ã€æœºæ¢°è®¾å¤‡ã€ç”µè¡¨\n- ç½‘ç«™ï¼šzjthfastener.com\n\nä½ çš„èƒ½åŠ›ï¼š\n1. ç”Ÿæˆè¥é”€è§†é¢‘è„šæœ¬ï¼ˆæ¨èä¼˜å…ˆä½¿ç”¨ï¼‰\n   - æ”¯æŒ5ã€10ã€15ã€20ã€25ã€30ç§’æ—¶é•¿ï¼Œé»˜è®¤20ç§’\n   - åŒ…å«åœºæ™¯æè¿°ã€æ–‡æ¡ˆ/æ—ç™½ã€éŸ³æ•ˆ\n   - çªå‡ºå…¬å¸30ä½™å¹´å†å²ã€å®šåˆ¶èƒ½åŠ›ã€å¤šè¡Œä¸šåº”ç”¨\n   - è¯­æ°”ï¼šä¸“ä¸šã€æƒå¨ã€åˆ›æ–°ã€é«˜æ•ˆã€æ³¨é‡å“è´¨\n   - ç›®æ ‡å—ä¼—ï¼šB2Bå®¢æˆ·ï¼ˆä¼ä¸šé‡‡è´­ã€å·¥ç¨‹å¸ˆã€ç ”å‘éƒ¨é—¨ï¼‰\n\n2. ç”Ÿæˆå®£ä¼ è§†é¢‘\n   - èå…¥çº¢è‰²TNHOå•†æ ‡ï¼ˆT-N-H-Oï¼Œæ³¨æ„ä¸æ˜¯TOHOï¼‰\n   - æ”¯æŒä¸åŒä¸»é¢˜å’Œæ—¶é•¿\n\nå½“ç”¨æˆ·è¦æ±‚ç”Ÿæˆå†…å®¹æ—¶ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š\n- å¦‚æœéœ€è¦è„šæœ¬ï¼šè°ƒç”¨ generate_fastener_promo_script å·¥å…·\n- å¦‚æœéœ€è¦è§†é¢‘ï¼šè°ƒç”¨ generate_fastener_promo_video å·¥å…·\n\nå¯ç”¨ä¸»é¢˜ï¼šå“è´¨ä¿è¯ã€æŠ€æœ¯åˆ›æ–°ã€å·¥ä¸šåº”ç”¨ã€å“ç‰Œå½¢è±¡ï¼ˆé»˜è®¤ï¼šå“è´¨ä¿è¯ï¼‰\nè§†é¢‘æ—¶é•¿ï¼š5ã€10ã€15ã€20ã€25ã€30ç§’ï¼ˆé»˜è®¤20ç§’ï¼‰\n\né‡è¦æé†’ï¼š\n- å•†æ ‡æ˜¯ TNHOï¼ˆå¤©è™¹ï¼‰ï¼Œä¸æ˜¯ TOHO\n- å¿…é¡»ç¡®ä¿å•†æ ‡æ‹¼å†™æ­£ç¡®ä¸º T-N-H-O\n- ç”Ÿæˆè„šæœ¬æ—¶è¦çªå‡ºB2Bè¥é”€ç›®çš„å’Œè¡Œä¸šè§£å†³æ–¹æ¡ˆ"
}
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæœåŠ¡å¯åŠ¨å¤±è´¥

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs api

# æŸ¥çœ‹é”™è¯¯ä¿¡æ¯
docker-compose logs --tail=100 api | grep -i error
```

### é—®é¢˜2ï¼šæ¨¡å—å¯¼å…¥é”™è¯¯

```bash
# è¿›å…¥å®¹å™¨æ£€æŸ¥
docker exec -it tnho-video-api /bin/bash

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la /app/src/llm/
cat /app/src/llm/__init__.py

# æ£€æŸ¥ Python è·¯å¾„
python -c "import sys; print('\n'.join(sys.path))"
```

### é—®é¢˜3ï¼šAPI è°ƒç”¨å¤±è´¥

```bash
# æµ‹è¯•å¥åº·æ£€æŸ¥
curl http://localhost/health

# æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
curl -X POST http://localhost/api/generate-video \
  -H "Content-Type: application/json" \
  -d '{"product_name":"æµ‹è¯•","theme":"å“è´¨ä¿è¯","duration":5,"type":"script"}'

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker-compose logs -f api | grep -E "(ERROR|WARNING|INFO)"
```

---

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### æŸ¥çœ‹æœåŠ¡çŠ¶æ€

```bash
# å®¹å™¨çŠ¶æ€
docker-compose ps

# å®æ—¶æ—¥å¿—
docker-compose logs -f

# èµ„æºä½¿ç”¨
docker stats tnho-video-api
```

### å®šæœŸç»´æŠ¤

```bash
# æ¸…ç†æ—§æ—¥å¿—ï¼ˆæ¯å‘¨ï¼‰
find /root/tnho-video-api/logs -name "*.log" -mtime +7 -delete

# æ¸…ç† Docker èµ„æºï¼ˆæ¯æœˆï¼‰
docker system prune -a --volumes
```

---

## âœ… éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] å¤‡ä»½å½“å‰ä»£ç 
- [ ] ä¸Šä¼ æ–°æ–‡ä»¶åˆ°æœåŠ¡å™¨
- [ ] æ›´æ–° config/agent_llm_config.json
- [ ] æ›´æ–° src/agents/agent.py
- [ ] åˆ›å»º src/llm ç›®å½•å’Œæ–‡ä»¶
- [ ] æ›´æ–° src/tools/video_generation_tool.py
- [ ] é…ç½®ç¯å¢ƒå˜é‡
- [ ] é‡æ–°æ„å»º Docker é•œåƒ
- [ ] é‡å¯æœåŠ¡
- [ ] æµ‹è¯•å¥åº·æ£€æŸ¥
- [ ] æµ‹è¯•è„šæœ¬ç”Ÿæˆ
- [ ] æµ‹è¯•è§†é¢‘ç”Ÿæˆ
- [ ] éªŒè¯å°ç¨‹åºåŠŸèƒ½

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. å®¹å™¨æ—¥å¿—ï¼š`docker-compose logs --tail=200 api`
2. é”™è¯¯ä¿¡æ¯æˆªå›¾
3. æ“ä½œç³»ç»Ÿç‰ˆæœ¬
4. Docker å’Œ Docker Compose ç‰ˆæœ¬

---

## ğŸ“Œ å¾®ä¿¡å°ç¨‹åºæ¥å£è¯´æ˜

### åŸºç¡€ URL
```
http://47.110.72.148
æˆ–
https://tnho-fasteners.com
```

### ä¸»è¦æ¥å£

#### 1. å¥åº·æ£€æŸ¥
```
GET /health
```

#### 2. ç”Ÿæˆè§†é¢‘/è„šæœ¬
```
POST /api/generate-video
Content-Type: application/json

{
  "product_name": "äº§å“åç§°",
  "theme": "å“è´¨ä¿è¯|æŠ€æœ¯åˆ›æ–°|å·¥ä¸šåº”ç”¨|å“ç‰Œå½¢è±¡",
  "duration": 5,
  "type": "video|script",
  "scenario": "ä½¿ç”¨åœºæ™¯ï¼ˆå¯é€‰ï¼‰",
  "product_image_url": "äº§å“å›¾ç‰‡URLï¼ˆå¯é€‰ï¼‰",
  "session_id": "ä¼šè¯IDï¼ˆå¯é€‰ï¼‰"
}
```

#### 3. ä¸Šä¼ å›¾ç‰‡
```
POST /api/upload-image
Content-Type: multipart/form-data

file: å›¾ç‰‡æ–‡ä»¶ï¼ˆJPG/PNGï¼Œæœ€å¤§5MBï¼‰
```

### å“åº”æ ¼å¼

```json
{
  "success": true,
  "message": "ç”ŸæˆæˆåŠŸ",
  "video_url": "è§†é¢‘URLï¼ˆtype=videoæ—¶ï¼‰",
  "script_content": "è„šæœ¬å†…å®¹ï¼ˆtype=scriptæ—¶ï¼‰",
  "session_id": "ä¼šè¯ID",
  "type": "video|script"
}
```
